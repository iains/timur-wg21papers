\input{wg21common}

\begin{document}
\title{Constant evaluation of Contracts}
\author{ Timur Doumler \small(\href{mailto:papers@timur.audio}{papers@timur.audio})}
\date{}
\maketitle

\begin{tabular}{ll}
Document \#: & P2894R1 \\
Date: &2023-11-06 \\
Project: & Programming Language C++ \\
Audience: & SG21
\end{tabular}

\begin{abstract}
This paper proposes semantics for contract checks during constant evaluation. We propose that during constant evaluation, contract checks should be evaluated with an implementation-defined choice of \emph{ignore}, \emph{enforce}, or \emph{observe} semantics, analogous to their runtime counterparts; in a manifestly constant-evaluated context, a contract check with a checked semantic and a predicate that is not a core constant expression renders the program ill-formed, while a contract check that evaluates to \tcode{false} emits a diagnostic (\emph{observe}) or renders the program ill-formed (\emph{enforce}). Special rules are needed for the case of evaluating contract checks in the initialiser of a non-\tcode{constexpr} variable usable in constant expressions; two different options are possible.
\end{abstract}

\section{Introduction}
\label{sec:intro}

In order to deliver a Contracts facility for Standard C++ (see \cite{P2695R1}), we need to produce a complete specification for the behaviour of contract checks both at compile time and at runtime. The specification currently in development (see \cite{P2900R1}) still has some design holes (see \cite{P2896R0}). One of these design holes is the question of how contract checks should behave during constant evaluation. In this paper, we develop a solution to this question.

This question has first been discussed in the appendices of \cite{P2834R1}. The solution proposed there no longer applies, since it is tied to the notion of checked and unchecked build modes, which was removed with the adoption of \cite{P2877R0}. An updated solution is proposed in \cite{P2932R1} section 3.3, derived from the  principles proposed in \cite{P2932R1} section 2. In this paper, we instead derive a solution from practical considerations: how would C++ users expect contract checks to behave when evaluated at compile time, and how can we best meet their needs? As we will see, the specification we arrive at in this paper is mostly identical to the one proposed in \cite{P2932R1} section 3.3.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}

\subsection{To consteval or to not consteval}

The first question that arises is whether we should consider contract checks during constant evaluation at all.

On the one hand, for many users the answer will be ``yes''. While we may think of contract checks primarily as a tool to identify bugs at runtime, similarly to \tcode{assert} macros today, contract checks can undoubtedly be useful at compile time, too. Such checks provide immediate value for \tcode{constexpr} functions that can be evaluated either at compile time or during runtime: for program correctness it is desirable to identify bugs in such function calls at compile time where possible. Consider the following program:

\begin{codeblock}
int f(int i) constexpr 
  pre (i > 0);

int main() {
  std::array<int, f(0)> a;  // out-of-contract call during constant evaluation
  // ...
}
\end{codeblock}

Going beyond issuing compiler diagnostics in cases like the above, it is desirable to have a solid framework for contract checks at compile time if we wish to expand usage of Contracts in C++ to use cases like static analysis and formal program verification. 

On the other hand, for many users the answer might be ``no''. Evaluating contract checks at compile time has the potential to significantly increase compile times, which is already a huge problem in many domains where C++ is used. Forcing compile-time contract checking on every user of C++ will likely result in many users wrapping their contract checks into macros to be able to ignore them at compile time, or even worse, not adopting Contracts in C++ at all.

The answer is therefore that we must give the user both options. Whether contract checks are evaluated during constant evaluation should be implementation-defined, allowing implementations to offer both options, e.g. through compiler flags.

\subsection{Contract semantics \emph{ignore} and \emph{enforce} at compile time}

In a previous revision of this paper, we suggested that letting the user choose whether they want to evaluate their contract checks at compile time could be accomplished by making it implementation-defined whether contract checks in the program are checked during constant evaluation or not, essentially introducing a ``global switch'' for turning compile-time contract checking on or off. We since realised that this is insufficient, because this setting might be different from one translation unit (TU) to another. Moreover, for an inline function that has contract checks in a shared header, this setting might be different from one constant evaluation of a contract check to another constant evaluation of the same contract check; such cases must not be considered ODR violations.

The answer is therefore that we should adopt the same approach for constant evaluation of any given contract check as we already do in the Contracts MVP \cite{P2900R1} for \emph{runtime} evaluation of any such contract check: that the \emph{contract semantic} of every contract check is implementation-defined and can vary from contract check to contract check and also from one evaluation of a contract check to another evaluation of the same contract check.

At runtime, there are three possible contract semantics in the Contracts MVP: the \emph{unchecked} semantic, \emph{ignore}, and the \emph{checked} semantics, \emph{enforce} and \emph{observe}. The \emph{ignore} semantic can be extended to constant evaluation in a straightforward way: do nothing\footnote{Note that even though the \emph{ignore} semantic means that a contract is not evaluated (neither at compile time nor at runtime), its predicate is still parsed (so it must be a valid expression) and the entities in the predicate are still ODR-used.}. The same is true for the \emph{enforce} semantic:  we can say that an \emph{enforce}d contract check is checked during constant evaluation, and if this check fails, a compiler diagnostic is issued (which is the compile-time analogue of the default contract-violation handler printing a diagnostic message at runtime) and the program is ill-formed (which is the compile-time analogue of terminating the program after the contract-violation handler returns). The only difference is that constant evaluation has no compile-time analogue for installing a user-defined contract-violation handler: as a user-replaceable function that is added at link time, a user-defined contract-violation handler is inherently a runtime-only feature.

\subsection{Contract semantic \emph{observe} at compile time}

It turns out that the \emph{observe} semantic has a useful compile-time implementation as well: an \emph{observe}d contract check is checked during constant evaluation, and if this check fails, a compiler diagnostic is issued; however, unlike an \emph{enforce}d contract check, this does not render the program ill-formed, which means the compiler can keep going. This is useful for the same reason that the \emph{observe} contract semantic is useful at runtime: it allows to introduce new contract checks to an existing legacy codebase without that codebase immediately breaking if a contract violation is detected.

We initially had concerns about enabling the \emph{observe} semantic for constant evaluation, because it seems to introduce a novelty: a normative diagnostic that does not render the program ill-formed, a ``standard warning''. However, after some discussion it turned out that we already have precedent for such a thing in the Standard since we introduced \tcode{\#warning} \cite{P2437R1} for C++23. The fact that the latter is a preprocessor directive rather than a ``proper'' language feature does not seem like a substantial difference.

\subsection{Compile-time semantic is independent of runtime semantic}

The approach proposed here can be described as essentially taking the block of pseudocode in \cite{P2900R1} section 2.4.10 which describes the mechanics of contract-violation handling, making both \tcode{__current_semantic()} and \tcode{__check_predicate()} compiler intrinsics \tcode{constexpr}-enabled, and then adding a \tcode{std::is_constant_evaluated() == true} branch to the algorithm.

One important property of this approach is that since the contract semantic of any given contract check can vary from evaluation of that contract check to the next evaluation of the same contract check, it is also perfectly confirming to use one contract semantic for all constant evaluations and another contract semantic for all runtime evaluations of a given contract check. This can be very useful since there are plausible use cases for such a setup. For example, in a debug build of a large and slow-to-compile application, one might want to disable contract checks at compile time to speed up compilation (minimising turnaround time during development), while at the same time enabling contract checks at runtime. Our approach enables this and many other use cases by making the contract semantic implementation-defined both at compile time and at runtime, following the spirit of \cite{P2877R0}.

\subsection{Possible outcomes of constant evaluation}

When a contract check is evaluated during constant evaluation, there are three possible outcomes:
\begin{itemize}
\item The predicate is a core constant expression that evaluates to \tcode{true},
\item The predicate is not a core constant expression,
\item The predicate is a core constant expression that does not evaluate to \tcode{true}.
\end{itemize}
Our first observation is that we do not need to specify anything further for the first case, the ``happy path'': if a contract check is evaluated during constant evaluation, the predicate of that contract check is a core constant expression, and that expression evaluates to \tcode{true}, then the obvious semantics of such a contract check are that it simply has no semantic effect whatsoever. In the remainder of this paper, it is sufficient to study only the second and third case.

\subsection{Contracts that cannot be checked at compile time}

What should happen if a contract check with a checked semantic at compile time has a predicate that is not a core constant expression, i.e. cannot be evaluated at compile time?

First of all, note that since \cite{P2448R2} was adopted for C++23, we do not need to do anything about contract checks on a \tcode{constexpr} or \tcode{consteval} function if that function is not actually called during constant evaluation:

\begin{codeblock}
bool pred();  // predicate not \tcode{constexpr}

int f() constexpr
  pre (pred());  // OK; never called during constant evaluation
  
int g() consteval
  pre (pred());  // OK: never called

int main() {
  return f();  // not a constant evaluation of \tcode{f}
  // \tcode{g} never called
}
\end{codeblock}

For \tcode{f}, the contract check is only ever checked during runtime, and therefore will have the same semantics as it always does; for \tcode{g}, the contract check is never checked at all. This program is therefore well-formed.

The only interesting case is: what should happen if the compiler actually encounters such a predicate during constant evaluation (we do not have to distinguish between \tcode{constexpr} and \tcode{consteval} here)? For example, consider the following program:

\begin{codeblock}
bool pred();  // predicate not \tcode{constexpr}

int f() constexpr
  pre (pred());  // ???

int main() {
  std::array<int, f()> a;  // constant evaluation of \tcode{f}
  // ...
}
\end{codeblock}

One possibility is to specify that if the predicate is not a core constant expression, the entire contract check is not a core constant expression. This would give a compiler error in the case above and many similar cases. However, it turns out that it is possible to SFINAE on whether an expression is a constant expression and therefore follow a different codepath depending on whether a contract is evaluated at compile time; \cite{P2932R1} section 3.3 has an example of such code. We do not believe that it makes any sense to allow such strange control flow. The answer is therefore to make this case ill-formed when using a checked contract semantic at compile time.

Conceptually, this specification makes sense. Consider the following function:

\begin{codeblock}
int do_something(int i)
  pre (i > 0)
  pre (hardware_thingy_available());  // not \tcode{constexpr}
\end{codeblock}

Ignoring the precondition that is not checkable at compile time when using a checked contract semantic at compile time would be wrong, because if the precondition is not checkable at compile time it is also not \emph{satisfiable} at compile time: the ``hardware thingy'' is literally not available while compiling the code, therefore calling the function at compile time is a precondition violation. If the user wishes to say that it is still \emph{correct} to call the function at compile time, even though the ``hardware thingy'' does not become available until runtime, they need to express that in their preconditions:

\begin{codeblock}
constexpr bool can_do_something() {
  if (!std::is_constant_evaluated())
    return hardware_thingy_available();
}

int do_something(int i)
  pre (i > 0)
  pre (can_do_something());  // OK
\end{codeblock}

\subsection{Contract violation at compile time}

What can happen if a contract check is evaluated during constant evaluation, the predicate of that contract check is a core constant expression, but that expression does not evaluate to \tcode{true}, i.e. we have identified a contract violation at compile time?

At runtime, there are many ways in which a predicate can \emph{not} evaluate to \tcode{true}:
\begin{itemize}
\item It can evaluate to \tcode{false},
\item It can throw an exception,
\item It can \tcode{longjmp},
\item It can terminate the program,
\item It can be undefined behaviour.
\end{itemize}
In the Contracts MVP, at runtime, we treat the first two cases as a contract violation; in all remaining cases, the user ``gets what they get'' (the behaviour ``escapes'' the contract check).

During constant evaluation, the situation is actually much simpler. You cannot throw an exception, you cannot \tcode{longjmp}, you cannot terminate the program, and there cannot be undefined behaviour; an expression that would do any of these things at runtime is not a core constant expression and therefore, as we already discussed above, for a checked contract semantic at compile time the program would be ill-formed in all these cases.

Therefore, the only way in which we could get a contract violation at compile time is if the predicate evaluates to \tcode{false}. As we already discussed above, in this case the compiler should issue a diagnostic, containing some information about the contract violation; in addition, if the semantic is \emph{enforce}, the program is ill-formed.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Trial constant evaluation}

Certain variables, despite not being \tcode{constexpr}, can be initialised statically (at compile time), in particular variables with static storage duration and \tcode{const} integers. However, the initialisation of such a variable will be relegated to \emph{dynamic} initialisation (at runtime) if the initialiser is not a core constant expression. The compiler may perform so-called \emph{trial} constant evaluation to determine whether to perform static or dynamic initialisation; see \href{https://eel.is/c++draft/expr.const#19.5}{[expr.const] 19.5} and \href{https://eel.is/c++draft/expr.const#footnote-73}{[expr.const] footnote 73}. Consider:

\begin{codeblock}
constexpr int f() { return 42; }
int g() { return 43; }  // not \tcode{constexpr}

static int j = f();     // static initialisation
static int i = g();     // dynamic initialisation

\end{codeblock}

This case contrasts with the \emph{manifestly constant-evaluated} contexts we have been discussing in this paper so far: contexts where the contract check would unambiguously happen at compile time (for example, if the contract check is on a function whose return value is used as a non-type template argument).

So far, this is nothing new. However, what should happen if the relegation from static initialisation to dynamic initialisation happens to be triggered by a contract check with a predicate that is not a core constant expression? Consider:

\begin{codeblock}
bool whatever();     // not \tcode{constexpr}

constexpr int f()
  pre(whatever()) {  // contract check not evaluable at compile time
  return 42;
}

static int i = f();  // ???
\end{codeblock}

On the one hand, if we just let these language features compose naturally, which is presumably what (at least some) users would expect, we just get the same result we would get if we added a call to \tcode{whatever} in the body of \tcode{f}: the contract check turns the static initialisation of \tcode{i} into dynamic initialisation.

On the other hand, just like with other similar cases such as a contract check triggering a lambda capture \cite{P2890R1} or a contract check triggering the deduction of a potentially-throwing exception specification \cite{P2969R0}, letting these language features compose naturally leads to violations of the \emph{zero overhead principle} from \cite{P2932R1}: the mere addition of a contract check causes the program to take a different branch at compile time, which in turn can cause ``heisenbugs'' (a program contains a bug, we add a contract check to find the bug, but the contract check causes the program to take another branch where the bug does not exist) and measurable performance degradations.

Just like with these other cases, there are two possible approaches to this problem. One approach is that if your contract check caused the variable to be initialised at runtime, causing runtime overhead, then you get what you get because you wrote what you wrote; if you care about the variable being initialised statically in all cases, there is a straightforward way to achieve this by using \tcode{constexpr} or \tcode{constinit}. The other approach is that any possible violation of the zero overhead principle, no matter how contrived, must be avoided at all costs, because the existence of any cases where the introduction of contract checks can introduce performance degradations would be a major disincentive for the adoption of Contracts in C++.

Just like in our other papers, we do not advocate for the latter approach here, because we believe that carving out all these exceptions to the language rules to satisfy the zero overhead principle at all costs adds complexity to the C++ language and hurts its teachability, which is damaging to C++ in the long term. However, we do note that if SG21 decides to obey by the zero overhead principle in all cases, it follows that the above code needs to be ill-formed.

The algorithm for achieving the latter would need to look as follows. First, we conduct a trial constant evaluation \emph{discarding} any contract checks that might otherwise be evaluated during that evaluation; if this trial constant evaluation fails and we relegate to dynamic initialisation, then the contract checks will end up being evaluated at runtime anyhow (or ignored, depending on contract semantic) and it therefore does not matter whether any of these contract predicates are core constant expressions. If however, the trial constant evaluation succeeds, we statically initialise the variable in question for real, this time \emph{including} constant evaluation of the contract checks we discarded earlier; if any of these contract predicates are not core constant expressions at this point, the program is ill-formed.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Non-evaluation}

There is one final variation on the theme of constant evaluation that is worth analysing. Let us consider a \tcode{constexpr} function that either is or is not a core constant expression, depending on which arguments are being passed in:

\begin{codeblock}
constexpr int divide(int n, int d) {
  return n / d;   // not a core constant expression if \tcode{d == 0}
}
\end{codeblock}

Now, we might want to add a contract check to prevent running into this case:

\begin{codeblock}
constexpr int divide(int n, int d)
  pre (d != 0) {  // contract predicate is always a core constant expression!
  return n / d; 
}
\end{codeblock}

Everything seems fine. If \tcode{divide} is called at compile time, we can enable compile-time checking of contracts and get a nice compiler diagnostic instead of a cryptic error that \tcode{n / d} is not a core constant expression. If \tcode{divide} is called at runtime, we can enable runtime checking of contracts to avoid the undefined behaviour.

However, what happens if we call \tcode{divide} while initialising one of those variables that may be initialised statically or dynamically?

\begin{codeblock}
int main() {
  const int i = divide(17,0);   // ???
}
\end{codeblock}

If we take the second of the options we discussed in the previous section and make it ill-formed for the addition of a contract check to trigger relegation of static initialisation to dynamic initialisation to satisfy the zero overhead principle, we end up in an odd situation. Trial evaluation to determine whether \tcode{divide(17,0)} is a core constant expression happens with the contract check discarded; this trial evaluation determines that the call is not a core constant expression (because of \tcode{n / d}) and delegates the call to runtime. As a result, the contract is never checked at compile time, \emph{even if we choose the enforce semantic for compile time}, and we instead run into a contract violation at runtime. This is a rather unfortunate example of the complexity introduced by sticking to the zero overhead principle in all cases: we end up with code that is extremely difficult to reason about, and in addition we end up failing to diagnose the error at compile time even though the compiler would be clearly capable of doing so. This result is somewhat explainable (trial evaluation is not \emph{actual} evaluation, so we cannot rely on the contract check being evaluated at compile time even when using a checked semantic at compile time) but that does not make it any less unfortunate.

However, if we instead take the first option, i.e. treating contract checks just like any other expression for the purposes of trial evaluation instead of discarding them, we get the desired result: a contract violation at compile time (when using a checked semantic at compile time).

\section{Summary}

In this paper, we have explored the design space of evaluating contract checks at compile time, one of the remaining design holes in the Contracts MVP \cite{P2900R1}. After having analysed how C++ users might expect contract checks to behave when evaluated at compile time, and how can we best meet their needs, we propose the following specification.

In a manifestly constant-evaluated context, contract checks should be evaluated with one of the three semantics, \emph{ignore}, \emph{enforce}, or \emph{observe}, analogous to their runtime counterparts. \emph{Observe} evaluates the predicate at compile time and issues a diagnostic in case a contract predicate evaluates to \tcode{false}; \emph{enforce} additionally makes the program ill-formed in this case. In a manifestly constant-evaluated context, either of the two checked semantics (\emph{enforce} or \emph{observe}) renders the program ill-formed if the contract predicate is not a core constant expression. Just like at runtime, it is implementation-defined (and thus left to the compiler to provide a selection mechanism for) which contract semantic is used for any given evaluation of a contract check.

Special rules are needed for the case of evaluating contract checks in the initialiser of a non-\tcode{constexpr} variable usable in constant expressions which might be statically or dynamically initialised depending on whether the initialiser is a core constant expression (which might be determined via a trial evaluation). Two different options are possible for specifying this case. The straightforward specification is to treat contract checks like any other expression for the purposes of trial  evaluation: if the contract predicate is not a core constant expression, initialisation of the variable is delegated to runtime.

This specification is straightforward but violates the zero overhead principle from \cite{P2932R1}: the addition of a contract check can in itself cause a variable to be initialised dynamically rather than statically. While there is a straightforward workaround for those who consider this a problem (just use \tcode{constexpr} or \tcode{constinit} if you need static initialisation), SG21 might end up deciding that the zero overhead principle must be satisfied in all possible cases without further code changes. If we go down that route, then we must discard contract checks for the purposes of trial evaluation, which satisfies the zero overhead principle, but adds significant complexity to the language and leads to strange and hard-to-reason-about cases where a contract violation that would get caught at compile time with the straightforward specification is instead only caught at runtime.

%\section*{Document history}

%\begin{itemize}
%\item \textbf{R0}, 2023-03-08: Initial version.
%\item \textbf{R1}, 20XX-XX-XX: ??
%\end{itemize}

\section*{Acknowledgements}

Thanks to Oliver Rosten and Ga\v sper A\v zman for their helpful feedback on an earlier version of this paper; thanks to Ville Voutilainen, Joshua Berne, Tom Honermann, Jason Merrill, and Jens Maurer for their helpful comments on the SG21 reflector thread that led to the current revision of this paper.

\renewcommand{\bibname}{References}
\bibliographystyle{abstract}
\bibliography{ref}

\end{document}
